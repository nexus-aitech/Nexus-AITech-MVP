import asyncio
import logging
import sys
import os
import random
import json
import requests
import pandas as pd
from datetime import datetime
from utils.logger import log_info, log_error
from ai_engine import DataAnalyzer
from database import fetch_real_data, store_analysis_result

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ…Ù¾ÙˆØ±Øª ØµØ­ÛŒØ­ Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§
sys.path.append(os.path.abspath(os.path.dirname(__file__) + "/.."))

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
logger = logging.getLogger("DataAnalysis")

# Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
data_analyzer = DataAnalyzer()

# Ø¢Ø¯Ø±Ø³ Ø³Ø±ÙˆØ± Ù…Ø±Ú©Ø²ÛŒ (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)
CORE_URL = os.getenv("CORE_URL", "http://localhost:5000/api/process")

def simulate_data_analysis(num_samples=10):
    """ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³ÛŒØ³ØªÙ… """
    try:
        data = {
            "feature_1": [random.uniform(0, 1) for _ in range(num_samples)],
            "feature_2": [random.randint(1, 100) for _ in range(num_samples)],
            "feature_3": [random.choice(["A", "B", "C"]) for _ in range(num_samples)],
            "timestamp": [datetime.utcnow() for _ in range(num_samples)]
        }
        
        df = pd.DataFrame(data)
        return df
    except Exception as e:
        log_error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {e}")
        return pd.DataFrame()

async def analyze_data():
    """ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
    log_info("ğŸ“Š Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ...")
    try:
        real_data = await fetch_real_data()
        analyzed_result = await data_analyzer.analyze(real_data)
        await store_analysis_result(analyzed_result, datetime.now())
    
        log_info(f"ğŸ“Š Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„: {json.dumps(analyzed_result, ensure_ascii=False)}")
    
        try:
            response = requests.post(CORE_URL, json={"bot_name": "data_analysis", "processed_data": analyzed_result}, timeout=5)
            if response.status_code == 200:
                data = response.json()
                log_info(f"âœ… Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø§Ø² Ø³Ø±ÙˆØ± Ù…Ø±Ú©Ø²ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {data.get('response', 'No response data')}")
            else:
                log_error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´ Ø§Ø² Core Coordinator! ÙˆØ¶Ø¹ÛŒØª: {response.status_code}")
        except requests.exceptions.ConnectionError:
            log_error("ğŸš¨ Core Coordinator Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª! ØªØ­Ù„ÛŒÙ„ Ù…Ø³ØªÙ‚Ù„ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯...")
        except requests.exceptions.Timeout:
            log_error("â³ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Core Coordinator ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª Ø´Ø¯. ØªØ­Ù„ÛŒÙ„ Ù…Ø­Ù„ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯.")
    except Exception as e:
        log_error(f"âš ï¸ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")

async def run_continuous_analysis():
    while True:
        await analyze_data()
        await asyncio.sleep(10)

# ÙÙ‚Ø· Ø§Ú¯Ø± Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯
if __name__ == "__main__":
    log_info("ğŸš€ Data Analysis Module Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ...")
    try:
        asyncio.run(run_continuous_analysis())
    except RuntimeError as e:
        log_error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Data Analysis: {e}")